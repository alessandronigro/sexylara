# MediaIntent + MediaUnderstanding Engine - Documentazione Completa

## ğŸ“‹ Panoramica

Il sistema **MediaIntent + MediaUnderstanding Engine** Ã¨ un modulo avanzato che permette agli NPC di ThrillMe di:

1. âœ… Riconoscere quando l'utente desidera contenuti multimediali
2. âœ… Distinguere tra foto, video e audio
3. âœ… Chiedere sempre conferma prima di generare media
4. âœ… **Analizzare immagini inviate dall'utente** (NUOVO)
5. âœ… **Analizzare audio inviato dall'utente** (NUOVO)
6. âœ… **Reagire in modo naturale e contestuale** (NUOVO)
7. âœ… **Aggiornare memoria e stato emotivo dell'NPC** (NUOVO)

---

## ğŸ—ï¸ Architettura Completa

### Componenti Implementati

```
backend/ai/engines/
â”œâ”€â”€ MediaIntentEngine.js          # Rileva intenti media in uscita
â”œâ”€â”€ VisionEngine.js                # Analizza immagini ricevute (NUOVO)
â”œâ”€â”€ AudioEngine.js                 # Analizza audio ricevuto (NUOVO)
â””â”€â”€ MediaUnderstandingEngine.js    # Orchestrazione analisi (NUOVO)

backend/services/
â””â”€â”€ MediaGenerationService.js      # Genera foto/video/audio

backend/
â”œâ”€â”€ brainEngine.js                 # Integrazione engines
â””â”€â”€ server-ws.js                   # WebSocket handler
```

---

## ğŸ¯ FunzionalitÃ  Dettagliate

### 1. MediaIntentEngine (Richieste Media)

**Rileva quando l'utente vuole ricevere media dall'NPC**

```javascript
const intent = MediaIntentEngine.detectIntent("voglio vederti");
// Returns: 'photo'

const isConfirm = MediaIntentEngine.isConfirmation("sÃ¬");
// Returns: true
```

**Pattern Riconosciuti:**
- **Foto**: "voglio vederti", "fammi un selfie", "mandami una foto"
- **Video**: "mandami un video", "fammi vedere come ti muovi"
- **Audio**: "voglio sentire la tua voce", "mandami un vocale"

**Flusso:**
```
User: "mandami una foto"
  â†“
AI: "Vuoi che ti mandi una foto mia? ğŸ˜˜"
  â†“
User: "sÃ¬"
  â†“
[Genera e invia foto]
```

---

### 2. VisionEngine (Analisi Immagini) ğŸ†•

**Analizza immagini inviate dall'utente usando OpenAI Vision API**

```javascript
const analysis = await VisionEngine.analyze(imageUrl);
```

**Output JSON:**
```json
{
  "persons": 1,
  "emotion": "felice",
  "gender": "male",
  "age_range": "25-35",
  "context": "selfie in camera con luce calda",
  "objects": ["telefono", "specchio"],
  "style": "selfie",
  "atmosphere": "calma",
  "clothing": "casual",
  "location": "interno",
  "lighting": "buona",
  "quality": "alta"
}
```

**Reazioni Generate:**
```javascript
const reaction = VisionEngine.generateReaction(analysis, npc);
// "Ti vedo sorridenteâ€¦ mi fai sentire subito meglio â¤ï¸"
```

**Emozioni Riconosciute:**
- `felice` â†’ "Che bel sorriso! Mi hai illuminato la giornata ğŸ˜Š"
- `triste` â†’ "Vorrei poterti abbracciare oraâ€¦ sembri davvero giÃ¹â€¦ ğŸ¥º"
- `arrabbiato` â†’ "Sento tensioneâ€¦ cosa ti ha fatto arrabbiare?"
- `neutrale` â†’ "Bella foto! Grazie per averla condivisa con me ğŸ“¸"
- `sorpreso` â†’ "Wow! Cosa ti ha sorpreso cosÃ¬ tanto? ğŸ˜®"

---

### 3. AudioEngine (Analisi Audio) ğŸ†•

**Trascrive e analizza audio usando Whisper + GPT**

```javascript
const analysis = await AudioEngine.analyze(audioFilePath);
```

**Output JSON:**
```json
{
  "text": "Ciao amore, come stai?",
  "emotion": "affettuoso",
  "tone": "dolce",
  "language": "it",
  "intensity": "media",
  "keywords": ["amore", "ciao"]
}
```

**Reazioni Generate:**
```javascript
const reaction = AudioEngine.generateReaction(analysis, npc);
// "Che dolceâ€¦ mi fai sciogliere il cuore ğŸ’•"
```

**Emozioni Riconosciute:**
- `felice` â†’ "Che bello sentirti cosÃ¬ felice! Mi hai contagiato ğŸ˜Š"
- `triste` â†’ "Sento la tristezza nella tua voceâ€¦ cosa Ã¨ successo? ğŸ¥º"
- `arrabbiato` â†’ "Sento la tensione nella tua voceâ€¦ cosa Ã¨ successo?"
- `affettuoso` â†’ "Che dolceâ€¦ mi fai sciogliere il cuore ğŸ’•"
- `ansioso` â†’ "Ti sento un po' teso/aâ€¦ va tutto bene?"

---

### 4. MediaUnderstandingEngine (Orchestrazione) ğŸ†•

**Coordina l'analisi e la reazione dell'NPC**

```javascript
const result = await MediaUnderstandingEngine.processReceivedMedia(
  'image',
  imageUrl,
  npc,
  userId
);
```

**Output:**
```json
{
  "analysis": { /* VisionEngine output */ },
  "reaction": "Ti vedo sorridenteâ€¦ mi fai sentire subito meglio â¤ï¸",
  "memoryRecord": {
    "type": "photo_received",
    "userId": "...",
    "userEmotion": "felice",
    "context": "selfie in camera",
    "attachmentImpact": +5
  },
  "emotionalImpact": {
    "attachment": +5,
    "intimacy": +0,
    "trust": +0,
    "mood": "happy"
  }
}
```

---

## ğŸ’¾ Aggiornamento Stato NPC

### Impatto Emotivo Calcolato

| Emozione Utente | Attachment | Intimacy | Trust | Mood NPC |
|-----------------|------------|----------|-------|----------|
| Felice          | +5         | 0        | 0     | happy    |
| Triste          | +10        | +5       | +5    | concerned|
| Affettuoso      | +15        | +10      | 0     | loving   |
| Arrabbiato      | +3         | 0        | 0     | worried  |

### Memoria NPC Aggiornata

```javascript
npc.media_memory = [
  {
    type: 'photo_received',
    userId: 'd0f56f12-...',
    timestamp: '2025-11-24T15:00:00Z',
    userEmotion: 'felice',
    context: 'selfie in camera con luce calda',
    npcReaction: 'interested',
    attachmentImpact: +5
  },
  // ... max 50 record
];
```

---

## ğŸ”„ Flusso Completo

### Scenario: Utente Invia Selfie Felice

```
1. User invia immagine via WebSocket
   {
     "text": "Guarda questa foto!",
     "mediaType": "image",
     "mediaUrl": "https://..."
   }

2. server-ws.js riceve il messaggio
   â†“
3. VisionEngine.analyze(imageUrl)
   â†’ Analisi: { emotion: "felice", style: "selfie", ... }
   â†“
4. MediaUnderstandingEngine.processReceivedMedia()
   â†’ Genera reazione: "Ti vedo sorridenteâ€¦ mi fai sentire subito meglio â¤ï¸"
   â†’ Calcola impatto: { attachment: +5, mood: "happy" }
   â†“
5. Aggiorna memoria NPC
   â†’ media_memory.push({ type: 'photo_received', ... })
   â†“
6. Genera prompt arricchito per AI
   â†’ "L'utente ti ha appena inviato una foto. Emozione: felice..."
   â†“
7. AI genera risposta naturale
   â†’ "Che bel sorriso! Mi hai illuminato la giornata ğŸ˜Š Bel selfie comunque! ğŸ¤³"
   â†“
8. Aggiorna stato emotivo in DB
   â†’ stats.attachment += 5
   â†’ current_mood = "happy"
   â†“
9. Invia risposta al client
```

---

## ğŸ“¡ Formato Messaggio WebSocket

### Invio Media dall'Utente

```json
{
  "text": "Messaggio opzionale",
  "traceId": "uuid",
  "girlfriend_id": "npc-id",
  "mediaType": "image",  // "image" | "audio" | "video"
  "mediaUrl": "https://storage.url/media.jpg"
}
```

### Risposta AI

```json
{
  "traceId": "uuid",
  "role": "assistant",
  "type": "chat",
  "content": "Ti vedo sorridenteâ€¦ mi fai sentire subito meglio â¤ï¸",
  "girlfriend_id": "npc-id"
}
```

---

## ğŸ§ª Test Suggeriti

### Test 1: Invio Selfie Felice
```javascript
// Client invia
{
  "text": "Guarda questa foto!",
  "mediaType": "image",
  "mediaUrl": "https://example.com/happy-selfie.jpg"
}

// Verifica:
// 1. AI riconosce emozione "felice"
// 2. Risponde con messaggio positivo
// 3. attachment aumenta di +5
// 4. mood diventa "happy"
```

### Test 2: Invio Vocale Triste
```javascript
// Client invia
{
  "text": "",
  "mediaType": "audio",
  "mediaUrl": "https://example.com/sad-voice.mp3"
}

// Verifica:
// 1. Whisper trascrive l'audio
// 2. GPT rileva emozione "triste"
// 3. AI risponde con empatia
// 4. attachment +10, intimacy +5, trust +5
// 5. mood diventa "concerned"
```

### Test 3: Richiesta Foto + Conferma
```javascript
// 1. User: "mandami una foto"
// 2. AI: "Vuoi che ti mandi una foto mia? ğŸ˜˜"
// 3. User: "sÃ¬"
// 4. AI: [genera e invia foto]
```

---

## âš™ï¸ Configurazione

### Variabili d'Ambiente Richieste

```bash
# OpenAI (per Vision e Whisper)
OPENAI_API_KEY=sk-...

# Replicate (per generazione immagini/video)
REPLICATE_API_TOKEN=r8_...
```

### Dipendenze NPM

```json
{
  "node-fetch": "^2.6.1",
  "form-data": "^4.0.0"
}
```

---

## ğŸ“Š Statistiche e Metriche

### Impatto Media su Relazione

| Tipo Media | Attachment Base | Note |
|------------|-----------------|------|
| Qualsiasi  | +5              | Base per condivisione |
| Audio      | +5 extra        | Voce Ã¨ piÃ¹ intima |
| Foto felice| +5 extra        | PositivitÃ  contagiosa |
| Foto triste| +10 extra       | VulnerabilitÃ  condivisa |
| Affettuoso | +15 extra       | Massimo impatto emotivo |

---

## ğŸš€ Deployment

Sistema giÃ  integrato e attivo:

```bash
# Riavvia WebSocket server
PORT=5001 pm2 restart ws --update-env

# Verifica log
pm2 logs ws
```

---

## ğŸ“š File Implementati

1. âœ… `/backend/ai/engines/MediaIntentEngine.js`
2. âœ… `/backend/ai/engines/VisionEngine.js` (NUOVO)
3. âœ… `/backend/ai/engines/AudioEngine.js` (NUOVO)
4. âœ… `/backend/ai/engines/MediaUnderstandingEngine.js` (NUOVO)
5. âœ… `/backend/services/MediaGenerationService.js`
6. âœ… `/backend/ai/brainEngine.js` (AGGIORNATO)
7. âœ… `/backend/server-ws.js` (AGGIORNATO)

---

## ğŸ¯ Prossimi Sviluppi

- [ ] Analisi video frame-by-frame
- [ ] Riconoscimento facciale per tracking identitÃ 
- [ ] Sentiment analysis su serie temporale di media
- [ ] Generazione media personalizzati basati su preferenze apprese
- [ ] Supporto per GIF animate
- [ ] Analisi contesto ambientale (luogo, ora del giorno)
- [ ] Integrazione con gruppi (media condivisi in gruppo)

---

**Stato**: âœ… Implementato e Attivo  
**Versione**: 2.0  
**Data**: 2025-11-24  
**Autore**: ThrillMe Development Team
