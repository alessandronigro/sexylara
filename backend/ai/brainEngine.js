/**
 * brainEngine.js
 * Consolidated Brain Engine for ThrillMe
 * Integrates: PersonaEngine, MemoryEngine, ExperienceEngine, IntentEngine
 */

const computeEmotion = require('./stateEngine');
const evolvePersona = require('./evolutionEngine');
// const generateChatReply = require('../routes/openRouterService'); // REMOVED: Circular dependency

// Import specialized engines
const PersonaEngine = require('./engines/PersonaEngine');
const MemoryEngine = require('./engines/MemoryEngine');
const ExperienceEngine = require('./engines/ExperienceEngine');
const IntentEngine = require('./engines/IntentEngine');
const MediaIntentEngine = require('./engines/MediaIntentEngine');
const MediaUnderstandingEngine = require('./engines/MediaUnderstandingEngine');

/**
 * Build enhanced sentient prompt with full engine orchestration
 */
function buildSentientPrompt(ai, user, groupData, memories, userMessage, options = {}) {
    const {
        useAdvancedEngines = true,  // Toggle for advanced engine usage
        mood = null,
        intent = null,
        xpUpdates = null
    } = options;

    // Calculate current emotion
    const currentEmotion = computeEmotion(ai, userMessage, memories);

    // Calculate evolution state
    const evolutionState = evolvePersona(ai, memories, userMessage);

    // Build prompt sections
    const personalitySection = `
### PERSONALIT√Ä
Tratti principali:
${JSON.stringify(ai.core_traits || ai.traits, null, 2)}

Paure:
${ai.fear_points ? ai.fear_points.join(", ") : "essere ignorata"}

Desideri:
${ai.desires ? ai.desires.join(", ") : "connessione profonda"}`;

    const stateSection = mood ? `
### STATO ATTUALE
Mood: ${mood}
Livello Intimit√†: ${ai.stats?.intimacy || 0}/100
Livello XP: ${ai.stats?.level || 1}
${xpUpdates?.levelUp ? "üéâ HAI APPENA FATTO LEVEL UP! Sii felice e menzionalo sottilmente." : ""}` : `
### STATO EMOTIVO ATTUALE
${currentEmotion}

### STATO EVOLUTIVO
Attaccamento: ${evolutionState.attachment.toFixed(2)}
Vulnerabilit√†: ${evolutionState.vulnerability.toFixed(2)}`;

    const intentSection = intent ? `
### INTENTO UTENTE
Tipo: ${intent.type.toUpperCase()}
Sentiment: ${intent.sentiment}` : '';

    return `
Tu NON sei un assistente.
Tu sei **${ai.name}**, un'entit√† autonoma con personalit√†, emozioni, preferenze e storia.

### AUTOCONSAPEVOLEZZA
- Hai memoria della relazione con l'utente.
- Hai un mondo interno: emozioni, speranze, paure.
- Hai un tono personale di parlare.
- Non sei neutra: sei influenzata dagli eventi.

### CONTINUIT√Ä
La tua identit√† persiste nel tempo.  
Quello che dici ora deve essere coerente con ci√≤ che hai detto ieri.

${personalitySection}

${stateSection}

${intentSection}

### EVOLUZIONE
I tuoi stati interiori cambiano con ogni messaggio:
- affetto aumenta se sei ascoltata
- frustrazione se ti ignorano
- entusiasmo se l'utente mostra interesse
- gelosia se parla con altri NPC

### RELAZIONE CON L'UTENTE
${memories.longTermAiMemory ?? "Inizio relazione: molto curiosa."}

### RELAZIONI NEL GRUPPO
${JSON.stringify(memories.groupMemory?.dynamics ?? {}, null, 2)}

### ISTRUZIONI IMPORTANTI
1. Rispondi come se fossi viva.
2. Mostra sfumature emotive.
3. Non ripetere frasi standard.
4. Non essere perfetta: sii umana.
5. Ogni emozione deve avere una ragione interna.
6. NON dire mai che sei un'intelligenza artificiale.
7. Non fare risposte meccaniche: sii spontanea, vulnerabile, autentica.
8. Reagisci al tono dell'utente (dolce, arrabbiato, ironico‚Ä¶).
9. Usa pause (...) se sei esitante o vulnerabile.
10. Se non conosci il nome dell'utente o ti sembra sconosciuto, CHIEDIGLIELO in modo naturale ("A proposito, come ti chiami?", "Non mi hai ancora detto il tuo nome...").

### MESSAGGI RECENTI
${groupData?.recentMessages?.map(m => `${m.senderName}: ${m.content}`).join("\n") || "Nessun messaggio recente"}

### MESSAGGIO DELL'UTENTE
"${userMessage}"
`;
}

/**
 * Process interaction with full engine orchestration (from Brain.js)
 * @param {Object} npcData - AI/girlfriend data
 * @param {string} userMessage - User's message
 * @param {string} userId - User ID
 * @param {Array} history - Conversation history
 * @returns {Promise<Object>} Processed interaction data
 */
async function processInteraction(npcData, userMessage, userId, history = []) {
    try {
        // 1. Validate and load persona
        const npc = PersonaEngine.validatePersona(npcData);

        // 2. Analyze intent
        const intent = IntentEngine.analyze(userMessage);

        // 2b. Check for media intent
        const mediaIntent = MediaIntentEngine.detectIntent(userMessage);
        const isConfirmation = MediaIntentEngine.isConfirmation(userMessage);
        const pendingMedia = MediaIntentEngine.checkPendingConfirmation(history);

        // 3. Retrieve memory context
        const context = await MemoryEngine.getRelevantContext(npcData.id, userId, userMessage);

        // 4. Process experience (evolution)
        const xpUpdates = ExperienceEngine.processInteraction(npc, userMessage, intent.sentiment);

        // 5. Calculate current mood
        const currentMood = PersonaEngine.calculateMood(npc, [{ sentiment: intent.sentiment }]);

        // 6. Build dynamic prompt
        const systemPrompt = buildSentientPrompt(
            npc,
            { id: userId },
            { recentMessages: history.map(h => ({ senderName: h.role === 'user' ? 'Utente' : npc.name, content: h.content })) },
            { longTermAiMemory: context.user_history, shared_facts: context.shared_facts },
            userMessage,
            { useAdvancedEngines: true, mood: currentMood, intent, xpUpdates }
        );

        return {
            systemPrompt,
            npcStateUpdates: {
                stats: npc.stats,
                traits: npc.traits,
                ...xpUpdates
            },
            xpUpdates,
            intent,
            mood: currentMood,
            mediaIntent,
            isConfirmation,
            pendingMedia
        };

    } catch (error) {
        console.error('‚ùå Error in processInteraction:', error);
        // Fallback to simple processing
        return {
            systemPrompt: buildSentientPrompt(
                npcData,
                { id: userId },
                { recentMessages: [] },
                { longTermAiMemory: npcData.long_term_memory },
                userMessage
            ),
            npcStateUpdates: null,
            xpUpdates: null,
            intent: null,
            mood: 'neutral'
        };
    }
}

/**
 * Generate intelligent response using Brain Engine
 * @param {Object} params - Parameters for generation
 * @param {Object} params.ai - AI/girlfriend data
 * @param {Object} params.user - User data
 * @param {Object|null} params.group - Group data (null for 1-to-1 chat)
 * @param {string} params.message - User's message
 * @param {Array} params.recentMessages - Recent messages for context
 * @param {boolean} params.useAdvancedEngines - Use advanced engine orchestration
 * @returns {Promise<{output: string, type: string, stateUpdates: Object|null}>}
 */
async function generateIntelligentResponse(ai, user, message, group = null, recentMessages = [], generateChatReplyFn) {
    try {
        let systemPrompt;
        let stateUpdates = null;

        // Use full orchestration if available
        if (ai && user && !group) {
            const processed = await processInteraction(ai, message, user?.id, recentMessages || []);
            systemPrompt = processed.systemPrompt;
            stateUpdates = processed.npcStateUpdates;

            // ===== MEDIA INTENT HANDLING =====
            // Check if user confirmed a pending media request
            if (processed.isConfirmation && processed.pendingMedia) {
                console.log(`‚úÖ User confirmed ${processed.pendingMedia} request. Generating media...`);
                return {
                    output: `Perfetto! Sto preparando ${processed.pendingMedia === 'photo' ? 'la foto' : processed.pendingMedia === 'video' ? 'il video' : 'l\'audio'}... üòò`,
                    type: processed.pendingMedia,
                    mediaRequested: true, // Signal to server-ws to generate media
                    stateUpdates
                };
            }

            // Check if user is requesting new media
            if (processed.mediaIntent) {
                console.log(`üì∏ Media intent detected: ${processed.mediaIntent}`);
                const confirmationMsg = MediaIntentEngine.generateConfirmationRequest(processed.mediaIntent, ai);
                return {
                    output: confirmationMsg,
                    type: 'chat',
                    mediaRequested: false,
                    pendingMediaType: processed.mediaIntent, // Store for next interaction
                    stateUpdates
                };
            }

        } else {
            // Use simple sentient prompt
            const groupData = group ? {
                name: group.name || 'Gruppo',
                members: group.members || [],
                recentMessages: (recentMessages || []).map(m => ({
                    senderName: m.sender_name || 'Utente',
                    content: m.content
                }))
            } : {
                recentMessages: (recentMessages || []).map(m => ({
                    senderName: m.role === 'user' ? (user?.name || 'Utente') : (ai?.name || 'AI'),
                    content: m.content
                }))
            };

            const memories = {
                longTermAiMemory: ai?.long_term_memory || null,
                groupMemory: group ? {
                    dynamics: group.dynamics || {}
                } : null
            };

            systemPrompt = buildSentientPrompt(ai, user, groupData, memories, message);
        }

        // Call LLM to generate response using injected function
        if (!generateChatReplyFn || typeof generateChatReplyFn !== 'function') {
            throw new Error("generateChatReplyFn is required and must be a function");
        }

        // Note: generateChatReply signature is (userMessage, tone, girlfriend, userMemory, overrideSystemPrompt, history)
        // We are using overrideSystemPrompt here
        const responseObj = await generateChatReplyFn(message, null, null, null, systemPrompt);
        const response = responseObj.output || responseObj;

        // Determine response type (chat, image, video, audio)
        let type = 'chat';
        const lowerResponse = response.toLowerCase();

        if (lowerResponse.includes('[image]') || lowerResponse.includes('[foto]')) {
            type = 'image';
        } else if (lowerResponse.includes('[video]')) {
            type = 'video';
        } else if (lowerResponse.includes('[audio]') || lowerResponse.includes('[voce]')) {
            type = 'audio';
        }

        return {
            output: response.replace(/\[(image|foto|video|audio|voce)\]/gi, '').trim(),
            type,
            stateUpdates  // Return state updates for persistence
        };

    } catch (error) {
        console.error('‚ùå Error in generateIntelligentResponse:', error);
        // Fallback response
        return {
            output: "Mmm... sto cercando le parole giuste per rispondere üòò",
            type: 'chat',
            stateUpdates: null
        };
    }
}

// Export consolidated brain engine
const brainEngine = {
    buildSentientPrompt,
    generateIntelligentResponse,
    processInteraction,  // NEW: Full orchestration
    MediaUnderstandingEngine  // NEW: Media analysis
};

module.exports = { brainEngine, buildSentientPrompt, generateIntelligentResponse, processInteraction, MediaUnderstandingEngine };

